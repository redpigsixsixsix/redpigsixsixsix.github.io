---
title:  "利用LSTM方法预测BTC价格"
layout: post
---

# 什么是LSTM
循环神经网络（Recurrent Neural Network，RNN）是一种用于处理序列数据的神经网络。相比一般的神经网络来说，他能够处理序列变化的数据。比如某个单词的意思会因为上文提到的内容不同而有不同的含义，RNN就能够很好地解决这类问题。
LSTM是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。LSTM有三个门：更新门、遗忘门和输出门。更新和忘记门决定是否更新单元的每个元素。    

LSTM内部有三个阶段:
1. 忘记阶段：这个阶段主要是对上一个节点传进来的输入进行选择性忘记。简单来说就是会"忘记不重要的，记住重要的"。
2. 选择记忆阶段：这个阶段的输入进行有选择性的进行记忆，主要是对输入进行选择。
3. 输出阶段：这个阶段决定哪些将会当成当前状态的输出。

![image.png](https://i.loli.net/2021/10/26/oUBEwGvMWOflgDP.png)

他的核心思想就是细胞状态，水平线在图上方贯穿运行，细胞状态类似于传送带，直接在整个链上运行，只有一些少量的信息交互。因此如果想让信息保持不变的话会很容易。

![image](https://user-images.githubusercontent.com/67320649/138860697-9c26a0cf-e57c-4a69-aacb-9fb1e469909d.png)

LSTM有通过精心设计的称作门的结构来去除或者增加信息到细胞的能力。门是一种让信息选择式通过的方法，包含一个`sigmoid`神经网络层和一个按位的乘法操作。  

![image](https://user-images.githubusercontent.com/67320649/138861434-d8fbf5b1-3789-4356-b8ae-0b00508adff9.png)

`sigmod`层输出0-1之间的数值，描述每个部分有多少量可以通过。0表示“不允许任何量通过”，1表示“允许任意量通过”。  
LSTM有三个门，保护和控制细胞状态。  

## LTSM的细节部分

LSTM中的第一步表示的是我们会从细胞状态中丢掉什么信息，这个决定通过**忘记门层**完成。这个门会读取 ![](http://latex.codecogs.com/gif.latex?h_{t-1}) 和 ![](http://latex.codecogs.com/gif.latex?x_{t})。  
输出一个0-1之间的数值，给 ![](http://latex.codecogs.com/gif.latex?C_{t-1}) 中的数字。

让我们回到语言模型的例子中来基于已经看到的预测下一个词。在这个问题中，细胞状态可能包含当前主语的性别，因此正确的代词可以被选择出来。当我们看到新的主语，我们希望忘记旧的主语。

![image](https://user-images.githubusercontent.com/67320649/138863033-a52da9f6-5520-4127-a51e-c815fa98f6ac.png)

下一步是确定什么样的新信息被存放在细胞状态中。这里包含两个部分。第一，`sigmoid`层称"输入门层"决定什么值我们将要更新。然后，一个 tanh 层创建一个新的候选值向量会被加入到状态中。下一步，我们会讲这两个信息来产生对状态的更新。  
在我们语言模型的例子中，我们希望增加新的主语的性别到细胞状态中，来替代旧的需要忘记的主语。

![image](https://user-images.githubusercontent.com/67320649/138863761-7f5d95df-c7b6-4f43-ab92-5ac1b506dfc0.png)

现在是更新旧细胞状态的时间了，![](http://latex.codecogs.com/gif.latex?C_{t-1}) 更新为 ![](http://latex.codecogs.com/gif.latex?C_{t}) 。前面的步骤已经决定了将会做什么，我们现在就是实际去完成。  
把旧状态和 ![](http://latex.codecogs.com/gif.latex?f_{t}) 相乘，丢弃掉我们确定需要丢弃的信息，接着加上 ![](http://latex.codecogs.com/gif.latex?i_{t}*C_{t})。这个就是新的候选值，根据我们决定更新每个状态的程序进行变化。  
在语言模型的例子中，这就是我们实际根据前面确定的目标，丢弃旧代词的性别信息并添加新的信息的地方。

![image](https://user-images.githubusercontent.com/67320649/138864408-a0e2c7ce-4abb-4448-a701-7a3c93decae9.png)

最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个`sigmoid`层来确定细胞状态的哪个部分将输出出去。接着，我们把细胞状态通过`tanh`进行处理（得到一个在-1到1之间的值）并将它和`sigmoid`门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。

在语言模型的例子中，因为他就看到了一个**代词**，可能需要输出与一个**动词**相关的信息。例如，可能输出是否代词是单数还是负数，这样如果是动词的话，我们也知道动词需要进行的词形变化。

![image](https://user-images.githubusercontent.com/67320649/138864950-4f4783e9-436a-4021-86a1-ec0620f6beb5.png)

# 使用LSTM对价格进行预测

这一部分研究一下怎么通过keras框架对BTC未来的价格进行预测。
